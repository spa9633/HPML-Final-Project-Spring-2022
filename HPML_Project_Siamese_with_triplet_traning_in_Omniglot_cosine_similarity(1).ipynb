{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y6BYwWeZoOen"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, Concatenate, BatchNormalization, concatenate, ReLU, LeakyReLU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import imageio\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPp23RyToWWQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Uj6kjAqFBf",
        "outputId": "48f04d13-2cea-4d92-aaf0-e4a581f033b6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6099305837637186822\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14465892352\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 17821900224085180173\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbLVvlXXqI-o",
        "outputId": "5785ecf4-8541-4c98-884c-2e10f28aae2d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/images_background/\n",
            "/content/images_evaluation/\n",
            "/content/\n"
          ]
        }
      ],
      "source": [
        "project_path = '/content/drive/My Drive/HPML_Project_Siamese_Networks_kpv222_spa9633/'\n",
        "\n",
        "train_zip_path = project_path + 'images_background.zip'\n",
        "validation_zip_path = project_path + 'images_evaluation.zip'\n",
        "\n",
        "train_folder = \"/content/images_background/\"\n",
        "val_folder = '/content/images_evaluation/'\n",
        "save_path = '/content/'\n",
        "print(train_folder)\n",
        "print(val_folder)\n",
        "print(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJYKhhbTqNMc",
        "outputId": "e05b83bb-1cdf-4a8a-b614-eb3633ff2875"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training folder zip extraction completed!\n",
            "Validation folder zip extraction completed!\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(train_zip_path, 'r') as z:\n",
        "  z.extractall()\n",
        "print(\"Training folder zip extraction completed!\")\n",
        "\n",
        "with ZipFile(validation_zip_path, 'r') as z:\n",
        "  z.extractall()\n",
        "print(\"Validation folder zip extraction completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-u4u4QV3oa0S"
      },
      "outputs": [],
      "source": [
        "def loadimgs(path,n = 0):\n",
        "    '''\n",
        "    path => Path of train directory or test directory\n",
        "    '''\n",
        "    X=[]\n",
        "    y = []\n",
        "    cat_dict = {}\n",
        "    lang_dict = {}\n",
        "    curr_y = n\n",
        "    # we load every alphabet seperately so we can isolate them later\n",
        "    for alphabet in os.listdir(path):\n",
        "        print(\"loading alphabet: \" + alphabet)\n",
        "        lang_dict[alphabet] = [curr_y,None]\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        # every letter/category has it's own column in the array, so  load seperately\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            cat_dict[curr_y] = (alphabet, letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "            # read all the images in the current category\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = imageio.imread(image_path)\n",
        "                category_images.append(image)\n",
        "                y.append(curr_y)\n",
        "            try:\n",
        "                X.append(np.stack(category_images))\n",
        "            # edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "            curr_y += 1\n",
        "            lang_dict[alphabet][1] = curr_y - 1\n",
        "    y = np.vstack(y)\n",
        "    X = np.stack(X)\n",
        "    return X,y,lang_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6LT7cnZqVRa",
        "outputId": "fedea6ad-9a65-4562-b0e6-8683f83c80c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading alphabet: Alphabet_of_the_Magi\n",
            "loading alphabet: Bengali\n",
            "loading alphabet: Arcadian\n",
            "loading alphabet: Japanese_(katakana)\n",
            "loading alphabet: N_Ko\n",
            "loading alphabet: Tagalog\n",
            "loading alphabet: Sanskrit\n",
            "loading alphabet: Armenian\n",
            "loading alphabet: Burmese_(Myanmar)\n",
            "loading alphabet: Early_Aramaic\n",
            "loading alphabet: Asomtavruli_(Georgian)\n",
            "loading alphabet: Anglo-Saxon_Futhorc\n",
            "loading alphabet: Hebrew\n",
            "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Cyrillic\n",
            "loading alphabet: Korean\n",
            "loading alphabet: Braille\n",
            "loading alphabet: Japanese_(hiragana)\n",
            "loading alphabet: Gujarati\n",
            "loading alphabet: Balinese\n",
            "loading alphabet: Latin\n",
            "loading alphabet: Mkhedruli_(Georgian)\n",
            "loading alphabet: Futurama\n",
            "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Grantha\n",
            "loading alphabet: Malay_(Jawi_-_Arabic)\n",
            "loading alphabet: Syriac_(Estrangelo)\n",
            "loading alphabet: Tifinagh\n",
            "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Greek\n"
          ]
        }
      ],
      "source": [
        "X,y,c = loadimgs(train_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSVsWMADuC33"
      },
      "outputs": [],
      "source": [
        "Xval,yval,cval = loadimgs(val_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aCoE-UHtAc9"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(save_path,\"train.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((X,c),f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_2Wd9WlZtHAv"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(save_path,\"val.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((Xval,cval),f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vz6M4wF1tX3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d94376-1746-4631-da70-d8f239286981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (964, 20, 105, 105)\n",
            "X_test shape: (659, 20, 105, 105)\n",
            "\n",
            "training alphabets\n",
            "['Alphabet_of_the_Magi', 'Bengali', 'Arcadian', 'Japanese_(katakana)', 'N_Ko', 'Tagalog', 'Sanskrit', 'Armenian', 'Burmese_(Myanmar)', 'Early_Aramaic', 'Asomtavruli_(Georgian)', 'Anglo-Saxon_Futhorc', 'Hebrew', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Cyrillic', 'Korean', 'Braille', 'Japanese_(hiragana)', 'Gujarati', 'Balinese', 'Latin', 'Mkhedruli_(Georgian)', 'Futurama', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Grantha', 'Malay_(Jawi_-_Arabic)', 'Syriac_(Estrangelo)', 'Tifinagh', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Greek']\n",
            "test alphabets:\n",
            "['Kannada', 'Aurek-Besh', 'Oriya', 'Mongolian', 'Gurmukhi', 'Manipuri', 'Keble', 'Sylheti', 'Tibetan', 'Atlantean', 'Old_Church_Slavonic_(Cyrillic)', 'Syriac_(Serto)', 'Tengwar', 'Malayalam', 'Angelic', 'Atemayar_Qelisayer', 'ULOG', 'Ge_ez', 'Avesta', 'Glagolitic']\n"
          ]
        }
      ],
      "source": [
        "PATH = save_path\n",
        "\n",
        "with open(os.path.join(PATH, \"train.pickle\"), \"rb\") as f:\n",
        "    (X_train, c_train) = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(PATH, \"val.pickle\"), \"rb\") as f:\n",
        "    (X_test, c_test) = pickle.load(f)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"\")\n",
        "print(\"training alphabets\")\n",
        "print([key for key in c_train.keys()])\n",
        "print(\"test alphabets:\")\n",
        "print([key for key in c_test.keys()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPoco6YofSp",
        "outputId": "441fe01a-45c8-48d6-8684-114e49915f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"leg\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 103, 103, 64)      640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 103, 103, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 103, 103, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 51, 51, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 51, 51, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 49, 49, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 49, 49, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 49, 49, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 24, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 22, 22, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 11, 11, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 11, 11, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 9, 9, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 9, 9, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              4195328   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,714,880\n",
            "Trainable params: 4,713,728\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Improved siamese model\n",
        "# define a convnet model to transforms data to an embeddings space. \n",
        "input_shape = (105, 105, 1)\n",
        "\n",
        "# The architecture is similar to that in the paper (Koch et al., \"Siamese Neural Networks for One-shot Image Recognition\"), \n",
        "# but we include dropout and batch normalization to improve generalization and speed up training.\n",
        "convnet = Sequential()\n",
        "convnet.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(ReLU())\n",
        "convnet.add(MaxPooling2D((2,2)))\n",
        "convnet.add(Dropout(0.2))\n",
        "\n",
        "convnet.add(Conv2D(128, (3,3)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(ReLU())\n",
        "convnet.add(MaxPooling2D((2,2)))\n",
        "convnet.add(Dropout(0.2))\n",
        "\n",
        "convnet.add(Conv2D(128, (3,3)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(ReLU())\n",
        "convnet.add(MaxPooling2D((2,2)))\n",
        "convnet.add(Dropout(0.2))\n",
        "\n",
        "convnet.add(Conv2D(256, (3,3)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(ReLU())\n",
        "convnet.add(MaxPooling2D((2,2)))\n",
        "convnet.add(Dropout(0.2))\n",
        "\n",
        "convnet.add(Flatten())\n",
        "\n",
        "convnet.add(Dense(1024, activation=\"linear\"))\n",
        "\n",
        "convnet._name = \"leg\"\n",
        "\n",
        "convnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNg7kWX-oiUA",
        "outputId": "1aebe2ce-6eb4-4c51-8091-30ada3362881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 3, 105, 105  0           []                               \n",
            "                                , 1)]                                                             \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 105, 105, 1)  0           ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 105, 105, 1)  0           ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 105, 105, 1)  0           ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " leg (Sequential)               (None, 1024)         4714880     ['lambda[0][0]',                 \n",
            "                                                                  'lambda_1[0][0]',               \n",
            "                                                                  'lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " merged_layer (Concatenate)     (None, 3072)         0           ['leg[0][0]',                    \n",
            "                                                                  'leg[1][0]',                    \n",
            "                                                                  'leg[2][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,714,880\n",
            "Trainable params: 4,713,728\n",
            "Non-trainable params: 1,152\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# The anchor, positive, negative image are merged together, as the input of the triplet network, then got split to get each one's neural codes.\n",
        "generated = Input(shape=(3, 105, 105, 1), name='input')\n",
        "\n",
        "anchor = Lambda(lambda x: x[:, 0])(generated)\n",
        "pos = Lambda(lambda x: x[:, 1])(generated)\n",
        "neg = Lambda(lambda x: x[:, 2])(generated)\n",
        "\n",
        "# merge the anchor, positive, negative embedding together, \n",
        "# let the merged layer be the output of triplet network\n",
        "anchor_embedding = convnet(anchor)\n",
        "pos_embedding = convnet(pos)\n",
        "neg_embedding = convnet(neg)  \n",
        "\n",
        "merged_output = concatenate([anchor_embedding, pos_embedding, neg_embedding], axis=-1, name='merged_layer')\n",
        "\n",
        "triplet_net = Model(inputs=generated, outputs=merged_output)\n",
        "triplet_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kJKKYOMAovgZ"
      },
      "outputs": [],
      "source": [
        "# Notice that the ground truth variable is not used for loss calculation. \n",
        "# It is used as a function argument to by-pass some Keras functionality.\n",
        "# This is because the network structure already implies the ground truth for the anchor image with the \"positive\" image.\n",
        "def triplet_loss(ground_truth, network_output):\n",
        "\n",
        "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)        \n",
        "    alpha = 0.2\n",
        "    distance1 = tf.keras.losses.cosine_similarity(anchor, positive)\n",
        "    distance2 = tf.keras.losses.cosine_similarity(anchor, negative)\n",
        "    return tf.keras.backend.clip(distance1 - distance2 + alpha, 0., None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jFv8CM7ko1P6"
      },
      "outputs": [],
      "source": [
        "# Notice that the returned  1 * np.zeros(batch_size) is to by-pass some Keras functionality, corresponding to ground_truth in tripletloss\n",
        "# We use a variable hard_selection to control which method we are going to use. If we set hard_selection == False, we will select triplets random,If we set the variable hard_selection == True, we will select hard triplets.\n",
        "def get_batch(batch_size, X, hard_selection):\n",
        "    # Create a subset of the model that basically represents a \"leg\" of the model\n",
        "    subset_model = Model(inputs=triplet_net.get_layer(\"leg\").get_input_at(0), \n",
        "                         outputs=triplet_net.get_layer(\"leg\").get_output_at(0))\n",
        "\n",
        "    while True:\n",
        "        n_classes, n_examples, w, h = X.shape\n",
        "        \n",
        "        # initialize result\n",
        "        triplets = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            triplet = [[], [], []]\n",
        "\n",
        "            # Pick one random class for anchor\n",
        "            anchor_class = np.random.randint(0, n_classes)\n",
        "\n",
        "            # Pick two different random pics for this class => idx_A and idx_P\n",
        "            [idx_A, idx_P] = np.random.choice(n_examples, size=2, replace=False)\n",
        "            #print(f\"Anchor class: {anchor_class}, idx_A: {idx_A}, idx_P: {idx_P}\")\n",
        "            \n",
        "            # Pick another class for negative, different from anchor_class\n",
        "            negative_class = np.random.choice(np.setdiff1d(range(0, n_classes), anchor_class))\n",
        "            # print(f\"Negative class: {negative_class}, shape: {X[negative_class].shape}\")\n",
        "\n",
        "            if not hard_selection:\n",
        "                # Pick a random pic from this negative class => N \n",
        "                idx_N = np.random.choice(n_examples, size=1, replace=False)\n",
        "\n",
        "            else:\n",
        "                # Pick a hardest pic from this negative class => N\n",
        "                \n",
        "                # Get the embedding of the anchor image\n",
        "                anchor_img = subset_model.predict(np.expand_dims(X[anchor_class][idx_A], axis=0))\n",
        "\n",
        "                # Make a prediction for all images in the negative class\n",
        "                neg_imgs = subset_model.predict(np.expand_dims(X[negative_class], axis=0).reshape(20, 105, 105, 1))\n",
        "                \n",
        "                # Compute the distance (note that we use the l2 distance) between the anchor and negative img embeddings\n",
        "                distances = [np.linalg.norm(anchor_img - neg_img) for neg_img in neg_imgs]\n",
        "\n",
        "                # Pick the image with the nearest distance as the \"hard\" image\n",
        "                idx_N = np.argsort(distances)[0]\n",
        "\n",
        "            triplet[0] = X[anchor_class][idx_A].reshape(w, h, 1)\n",
        "            triplet[1] = X[anchor_class][idx_P].reshape(w, h, 1)\n",
        "            triplet[2]=  X[negative_class][idx_N].reshape(w, h, 1)\n",
        "            triplets.append(triplet)\n",
        "\n",
        "        yield np.array(triplets), 1 * np.zeros(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7AWx8Gfzo4g3"
      },
      "outputs": [],
      "source": [
        "def make_oneshot_task(N, X, c, language=None):\n",
        "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "    indices = np.random.randint(0, n_examples, size=(N,))\n",
        "    if language is not None:\n",
        "        low, high = c[language]\n",
        "        if N > high - low:\n",
        "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
        "        categories = np.random.choice(range(low,high), size=(N,), replace=False)\n",
        "    else:  # if no language specified just pick a bunch of random letters\n",
        "        categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
        "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, 1)\n",
        "    support_set = X[categories, indices, :, :]\n",
        "    support_set[0, :, :] = X[true_category, ex2]\n",
        "    support_set = support_set.reshape(N, w, h, 1)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image, support_set]\n",
        "    return pairs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-BAWT1iNo-Yw"
      },
      "outputs": [],
      "source": [
        "def test_oneshot(model, X, c, N=20, k=250, language=None, verbose=True):     \n",
        "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
        "    n_correct = 0\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
        "\n",
        "    for i in range(k):\n",
        "        # Create a one-shot task \n",
        "        inputs, targets = make_oneshot_task(N, X, c, language=language)\n",
        "\n",
        "        # 1. For a given one-shot task, obtain embeddings for the test image as well as the support set. \n",
        "        test_img = model.predict(inputs[0])\n",
        "        support_set = model.predict(inputs[1])\n",
        "        # Note that we use the l2 distance to compute the distances\n",
        "        distances = [np.linalg.norm(x-y) for x,y in zip(test_img, support_set)]\n",
        "        \n",
        "        # 2. Pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction.\n",
        "        if np.argmin(distances) == np.argmax(targets):\n",
        "            n_correct += 1\n",
        "\n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
        "    return percent_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U4ruXvU_pDdP"
      },
      "outputs": [],
      "source": [
        "def train(model, X_train, hard_selection=False, batch_size=64, steps_per_epoch=100, epochs=1):\n",
        "    model.fit(get_batch(batch_size, X_train, hard_selection), steps_per_epoch=steps_per_epoch, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Mn_uvB-PpG1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f60800-0a0d-4d4b-c66f-05634cbc9618"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training loop 1 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 31s 175ms/step - loss: 0.0737\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 52.8% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 2 ===\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0560\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 50.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 3 ===\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0411\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 65.2% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 4 ===\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0307\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 56.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 5 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0276\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 66.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 6 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0251\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 62.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 7 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0257\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 70.8% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 8 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0231\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 71.2% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 9 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0233\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 69.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 10 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0211\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 68.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 11 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0205\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 69.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 12 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0208\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 73.6% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 13 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0204\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 74.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 14 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0172\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 75.2% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 15 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0173\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 69.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 16 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0181\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 69.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 17 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0171\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 72.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 18 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0162\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 72.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 19 ===\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0157\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 74.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 20 ===\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0137\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 74.4% accuracy for 20-way one-shot learning\n"
          ]
        }
      ],
      "source": [
        "# Random triplet selection\n",
        "triplet_net.compile(loss=triplet_loss, optimizer=Adam(lr=0.0001))\n",
        "loops = 20\n",
        "best_acc_random = 0\n",
        "t1 = time.time()\n",
        "for i in range(loops):\n",
        "    print(\"=== Training loop {} ===\".format(i+1))\n",
        "    # === ADD CODE HERE ===\n",
        "    train(triplet_net, X_train, hard_selection=False, batch_size=64, steps_per_epoch=100, epochs=1)\n",
        "    subset_model = Model(inputs=triplet_net.get_layer(\"leg\").get_input_at(0), \n",
        "                         outputs=triplet_net.get_layer(\"leg\").get_output_at(0))\n",
        "    test_acc = test_oneshot(subset_model, X_test, c_test)\n",
        "\n",
        "    if test_acc >= best_acc_random:\n",
        "        print(\"********* New best one-shot accuracy, saving model ********\")\n",
        "        triplet_net.save(os.path.join(\".\", \"triplet_net_with_random_selection.h5\"))\n",
        "        best_acc_random = test_acc\n",
        "    \n",
        "    if test_acc >= 80:\n",
        "      t2=time.time()\n",
        "      print(\"The time taken to reach 85% test accuracy is \", (t1-t2)/60, \"minutes\")\n",
        "      sys.exit(0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HPML_Project_Siamese_with_triplet_traning_in_Omniglot_cosine_similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}